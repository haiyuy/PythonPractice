{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d4f799c3e06f06",
   "metadata": {},
   "source": [
    "## 什么时候会想到降维？\n",
    "- **维度灾难**：特征维数远大于样本量或彼此高度相关时，很多算法会算不过来或预测不稳定。\n",
    "- **噪声过多**：冗余或高噪声特征会稀释模型关注点，降维可以先压缩再建模。\n",
    "- **可视化需求**：希望把几十上百维的数据压到 2/3 维，观察分布、异常或潜在分群。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa0684007835f2",
   "metadata": {},
   "source": [
    "## 降维的主要应用\n",
    "- **探索性可视化**：PCA、t-SNE、UMAP 可以帮助我们洞察高维结构。\n",
    "- **特征压缩**：主成分可以大幅降低特征数，减少计算量。\n",
    "- **噪声过滤**：删除贡献极小的方向，提升信噪比。\n",
    "- **模型预处理**：先降维再训练分类/回归器，有时泛化更稳定。#%%\n",
    "\n",
    "今天这几种降维算法只做简单介绍和代码展示，并未深入推导底层原理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a28253c96000abd",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c1b36ec3cb3d071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:16:12.730410Z",
     "start_time": "2025-11-30T12:16:12.673872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7500 entries, 0 to 7499\n",
      "Data columns (total 31 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Home Ownership                7500 non-null   int64  \n",
      " 1   Annual Income                 7500 non-null   float64\n",
      " 2   Years in current job          7500 non-null   float64\n",
      " 3   Tax Liens                     7500 non-null   float64\n",
      " 4   Number of Open Accounts       7500 non-null   float64\n",
      " 5   Years of Credit History       7500 non-null   float64\n",
      " 6   Maximum Open Credit           7500 non-null   float64\n",
      " 7   Number of Credit Problems     7500 non-null   float64\n",
      " 8   Months since last delinquent  7500 non-null   float64\n",
      " 9   Bankruptcies                  7500 non-null   float64\n",
      " 10  Long Term                     7500 non-null   int64  \n",
      " 11  Current Loan Amount           7500 non-null   float64\n",
      " 12  Current Credit Balance        7500 non-null   float64\n",
      " 13  Monthly Debt                  7500 non-null   float64\n",
      " 14  Credit Score                  7500 non-null   float64\n",
      " 15  Credit Default                7500 non-null   int64  \n",
      " 16  Purpose_business loan         7500 non-null   int32  \n",
      " 17  Purpose_buy a car             7500 non-null   int32  \n",
      " 18  Purpose_buy house             7500 non-null   int32  \n",
      " 19  Purpose_debt consolidation    7500 non-null   int32  \n",
      " 20  Purpose_educational expenses  7500 non-null   int32  \n",
      " 21  Purpose_home improvements     7500 non-null   int32  \n",
      " 22  Purpose_major purchase        7500 non-null   int32  \n",
      " 23  Purpose_medical bills         7500 non-null   int32  \n",
      " 24  Purpose_moving                7500 non-null   int32  \n",
      " 25  Purpose_other                 7500 non-null   int32  \n",
      " 26  Purpose_renewable energy      7500 non-null   int32  \n",
      " 27  Purpose_small business        7500 non-null   int32  \n",
      " 28  Purpose_take a trip           7500 non-null   int32  \n",
      " 29  Purpose_vacation              7500 non-null   int32  \n",
      " 30  Purpose_wedding               7500 non-null   int32  \n",
      "dtypes: float64(13), int32(15), int64(3)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "# 先运行之前预处理好的代码\n",
    "import pandas as pd\n",
    "import pandas as pd    #用于数据处理和分析，可处理表格数据。\n",
    "import numpy as np     #用于数值计算，提供了高效的数组操作。\n",
    "import matplotlib.pyplot as plt    #用于绘制各种类型的图表\n",
    "import seaborn as sns   #基于matplotlib的高级绘图库，能绘制更美观的统计图形。\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    " # 设置中文字体（解决中文显示问题）\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # Windows系统常用黑体字体\n",
    "plt.rcParams['axes.unicode_minus'] = False    # 正常显示负号\n",
    "data = pd.read_csv('data.csv')    #读取数据\n",
    "\n",
    "\n",
    "# 先筛选字符串变量 \n",
    "discrete_features = data.select_dtypes(include=['object']).columns.tolist()\n",
    "# Home Ownership 标签编码\n",
    "home_ownership_mapping = {\n",
    "    'Own Home': 1,\n",
    "    'Rent': 2,\n",
    "    'Have Mortgage': 3,\n",
    "    'Home Mortgage': 4\n",
    "}\n",
    "data['Home Ownership'] = data['Home Ownership'].map(home_ownership_mapping)\n",
    "\n",
    "# Years in current job 标签编码\n",
    "years_in_job_mapping = {\n",
    "    '< 1 year': 1,\n",
    "    '1 year': 2,\n",
    "    '2 years': 3,\n",
    "    '3 years': 4,\n",
    "    '4 years': 5,\n",
    "    '5 years': 6,\n",
    "    '6 years': 7,\n",
    "    '7 years': 8,\n",
    "    '8 years': 9,\n",
    "    '9 years': 10,\n",
    "    '10+ years': 11\n",
    "}\n",
    "data['Years in current job'] = data['Years in current job'].map(years_in_job_mapping)\n",
    "\n",
    "# Purpose 独热编码，记得需要将bool类型转换为数值\n",
    "data = pd.get_dummies(data, columns=['Purpose'])\n",
    "data2 = pd.read_csv(\"data.csv\") # 重新读取数据，用来做列名对比\n",
    "list_final = [] # 新建一个空列表，用于存放独热编码后新增的特征名\n",
    "for i in data.columns:\n",
    "    if i not in data2.columns:\n",
    "       list_final.append(i) # 这里打印出来的就是独热编码后的特征名\n",
    "for i in list_final:\n",
    "    data[i] = data[i].astype(int) # 这里的i就是独热编码后的特征名\n",
    "\n",
    "\n",
    "\n",
    "# Term 0 - 1 映射\n",
    "term_mapping = {\n",
    "    'Short Term': 0,\n",
    "    'Long Term': 1\n",
    "}\n",
    "data['Term'] = data['Term'].map(term_mapping)\n",
    "data.rename(columns={'Term': 'Long Term'}, inplace=True) # 重命名列\n",
    "continuous_features = data.select_dtypes(include=['int64', 'float64']).columns.tolist()  #把筛选出来的列名转换成列表\n",
    " \n",
    " # 连续特征用中位数补全\n",
    "for feature in continuous_features:     \n",
    "    mode_value = data[feature].mode()[0]            #获取该列的众数。\n",
    "    data[feature].fillna(mode_value, inplace=True)          #用众数填充该列的缺失值，inplace=True表示直接在原数据上修改。\n",
    "\n",
    "# 最开始也说了 很多调参函数自带交叉验证，甚至是必选的参数，你如果想要不交叉反而实现起来会麻烦很多\n",
    "# 所以这里我们还是只划分一次数据集\n",
    "\n",
    "data.drop(columns=['Id'], inplace=True) # 删除 Loan ID 列\n",
    "data.info() # 查看数据集的信息，包括数据类型和缺失值情况"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed52710813cf420",
   "metadata": {},
   "source": [
    "目前有 30 个特征，1 个标签。之后再看不同降维结果的特征数量和模型表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717648a62cae03f4",
   "metadata": {},
   "source": [
    "### 降维方法\n",
    "- **无监督降维**：PCA/SVD 关注整体方差，t-SNE、UMAP/LLE 更强调局部邻域结构。\n",
    "- **有监督降维**：LDA 借助标签让不同类别尽量分开、同类样本尽量聚集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e61de1606d65ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:16:14.269979Z",
     "start_time": "2025-11-30T12:16:12.817439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. 默认参数随机森林 (训练集 -> 测试集) ---\n",
      "训练与预测耗时: 0.9657 秒\n",
      "\n",
      "默认随机森林 在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.85      1059\n",
      "           1       0.76      0.30      0.43       441\n",
      "\n",
      "    accuracy                           0.77      1500\n",
      "   macro avg       0.77      0.63      0.64      1500\n",
      "weighted avg       0.77      0.77      0.73      1500\n",
      "\n",
      "默认随机森林 在测试集上的混淆矩阵：\n",
      "[[1018   41]\n",
      " [ 309  132]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop(['Credit Default'], axis=1)  # 特征，axis=1表示按列删除\n",
    "y = data['Credit Default'] # 标签\n",
    "# 按照8:2划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80%训练集，20%测试集\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier #随机森林分类器\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score # 用于评估分类器性能的指标\n",
    "from sklearn.metrics import classification_report, confusion_matrix #用于生成分类报告和混淆矩阵\n",
    "import warnings #用于忽略警告信息\n",
    "warnings.filterwarnings(\"ignore\") # 忽略所有警告信息\n",
    "# --- 1. 默认参数的随机森林 ---\n",
    "# 评估基准模型，这里确实不需要验证集\n",
    "print(\"--- 1. 默认参数随机森林 (训练集 -> 测试集) ---\")\n",
    "import time # 这里介绍一个新的库，time库，主要用于时间相关的操作，因为调参需要很长时间，记录下会帮助后人知道大概的时长\n",
    "start_time = time.time() # 记录开始时间\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train) # 在训练集上训练\n",
    "rf_pred = rf_model.predict(X_test) # 在测试集上预测\n",
    "end_time = time.time() # 记录结束时间\n",
    "\n",
    "print(f\"训练与预测耗时: {end_time - start_time:.4f} 秒\")\n",
    "print(\"\\n默认随机森林 在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "print(\"默认随机森林 在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0317f1ded71ee0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:16:18.703974Z",
     "start_time": "2025-11-30T12:16:14.311274Z"
    }
   },
   "outputs": [],
   "source": [
    "# 确保这些库已导入，你的原始代码中可能已经包含了部分\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler # 特征缩放\n",
    "from sklearn.decomposition import PCA # 主成分分析\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA # 线性判别分析\n",
    "# UMAP 需要单独安装: pip install umap-learn\n",
    "import umap # 如果安装了 umap-learn，可以这样导入\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 你的 X_train, X_test, y_train, y_test 应该已经根据你的代码准备好了\n",
    "# 我们假设你的随机森林模型参数与基准模型一致，以便比较降维效果\n",
    "# rf_params = {'random_state': 42} # 如果你的基准模型有其他参数，也在这里定义\n",
    "# 为了直接比较，我们使用默认的 RandomForestClassifier 参数，除了 random_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28b42f4016f5792",
   "metadata": {},
   "source": [
    "## PCA：寻找最大方差方向\n",
    "PCA 是一种线性降维方法，目标是找到信息量最大的正交主成分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd077b8878819853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:16:18.854948Z",
     "start_time": "2025-11-30T12:16:18.742460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. PCA 降维 + 随机森林 (不使用 Pipeline) ---\n",
      "为了保留95%的方差，需要的主成分数量: 26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "import numpy as np # 确保numpy导入\n",
    "\n",
    "# 假设 X_train, X_test, y_train, y_test 已经准备好了\n",
    "\n",
    "print(f\"\\n--- 2. PCA 降维 + 随机森林 (不使用 Pipeline) ---\")\n",
    "\n",
    "\n",
    "# 步骤 1: 特征缩放\n",
    "scaler_pca = StandardScaler()\n",
    "X_train_scaled_pca = scaler_pca.fit_transform(X_train)\n",
    "X_test_scaled_pca = scaler_pca.transform(X_test) # 使用在训练集上fit的scaler\n",
    "\n",
    "# 步骤 2: PCA降维\n",
    "# 选择降到10维，或者你可以根据解释方差来选择，例如：\n",
    "pca_expl = PCA(random_state=42)\n",
    "pca_expl.fit(X_train_scaled_pca)\n",
    "cumsum_variance = np.cumsum(pca_expl.explained_variance_ratio_)\n",
    "n_components_to_keep_95_var = np.argmax(cumsum_variance >= 0.95) + 1\n",
    "print(f\"为了保留95%的方差，需要的主成分数量: {n_components_to_keep_95_var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab40f687a2903c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:16:20.521696Z",
     "start_time": "2025-11-30T12:16:18.901911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA降维后，训练集形状: (6000, 10), 测试集形状: (1500, 10)\n",
      "手动PCA降维后，训练与预测耗时: 1.5966 秒\n",
      "\n",
      "手动 PCA + 随机森林 在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85      1059\n",
      "           1       0.70      0.32      0.44       441\n",
      "\n",
      "    accuracy                           0.76      1500\n",
      "   macro avg       0.73      0.63      0.64      1500\n",
      "weighted avg       0.75      0.76      0.73      1500\n",
      "\n",
      "手动 PCA + 随机森林 在测试集上的混淆矩阵：\n",
      "[[997  62]\n",
      " [298 143]]\n"
     ]
    }
   ],
   "source": [
    "# 我们测试下降低到10维的效果\n",
    "n_components_pca = 10\n",
    "pca_manual = PCA(n_components=n_components_pca, random_state=42)\n",
    "\n",
    "X_train_pca = pca_manual.fit_transform(X_train_scaled_pca)\n",
    "X_test_pca = pca_manual.transform(X_test_scaled_pca) # 使用在训练集上fit的pca\n",
    "\n",
    "print(f\"PCA降维后，训练集形状: {X_train_pca.shape}, 测试集形状: {X_test_pca.shape}\")\n",
    "start_time_pca_manual = time.time()\n",
    "# 步骤 3: 训练随机森林分类器\n",
    "rf_model_pca = RandomForestClassifier(random_state=42)\n",
    "rf_model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# 步骤 4: 在测试集上预测\n",
    "rf_pred_pca_manual = rf_model_pca.predict(X_test_pca)\n",
    "end_time_pca_manual = time.time()\n",
    "\n",
    "print(f\"手动PCA降维后，训练与预测耗时: {end_time_pca_manual - start_time_pca_manual:.4f} 秒\")\n",
    "\n",
    "print(\"\\n手动 PCA + 随机森林 在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, rf_pred_pca_manual))\n",
    "print(\"手动 PCA + 随机森林 在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, rf_pred_pca_manual))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa6fb79fec42e53",
   "metadata": {},
   "source": [
    "## t-SNE：保留局部邻域关系\n",
    "t-SNE 不再追求最大方差，而是希望相似样本依旧靠得近，适合探索潜在簇结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45f0312741c40a7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:17:46.691657Z",
     "start_time": "2025-11-30T12:16:20.608476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. t-SNE 降维 + 随机森林  ---\n",
      "       标准 t-SNE 主要用于可视化，直接用于分类器输入可能效果不佳。\n",
      "正在对训练集进行 t-SNE fit_transform...\n",
      "训练集 t-SNE fit_transform 完成，耗时: 72.08 秒\n",
      "正在对测试集进行 t-SNE fit_transform...\n",
      "测试集 t-SNE fit_transform 完成，耗时: 12.78 秒\n",
      "t-SNE降维后，训练集形状: (6000, 2), 测试集形状: (1500, 2)\n",
      "t-SNE降维数据上，随机森林训练与预测耗时: 1.1766 秒\n",
      "t-SNE 总耗时 (包括两次fit_transform和RF): 86.04 秒\n",
      "\n",
      "手动 t-SNE + 随机森林 在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.90      0.79      1059\n",
      "           1       0.22      0.07      0.10       441\n",
      "\n",
      "    accuracy                           0.66      1500\n",
      "   macro avg       0.46      0.48      0.45      1500\n",
      "weighted avg       0.56      0.66      0.59      1500\n",
      "\n",
      "手动 t-SNE + 随机森林 在测试集上的混淆矩阵：\n",
      "[[954 105]\n",
      " [411  30]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # 用于可选的可视化\n",
    "import seaborn as sns # 用于可选的可视化\n",
    "\n",
    "# 假设 X_train, X_test, y_train, y_test 已经准备好了\n",
    "# 并且你的 X_train, X_test 是DataFrame或Numpy Array\n",
    "\n",
    "print(f\"\\n--- 3. t-SNE 降维 + 随机森林  ---\")\n",
    "print(\"       标准 t-SNE 主要用于可视化，直接用于分类器输入可能效果不佳。\")\n",
    "\n",
    "\n",
    "# 步骤 1: 特征缩放\n",
    "scaler_tsne = StandardScaler()\n",
    "X_train_scaled_tsne = scaler_tsne.fit_transform(X_train)\n",
    "X_test_scaled_tsne = scaler_tsne.transform(X_test) # 使用在训练集上fit的scaler\n",
    "\n",
    "# 步骤 2: t-SNE 降维\n",
    "# 我们将降维到与PCA相同的维度（例如10维）或者一个适合分类的较低维度。\n",
    "# t-SNE通常用于2D/3D可视化，但也可以降到更高维度。\n",
    "# 然而，降到与PCA一样的维度（比如10维）对于t-SNE来说可能不是其优势所在，\n",
    "# 并且计算成本会显著增加，因为高维t-SNE的优化更困难。\n",
    "# 为了与PCA的 n_components=10 对比，我们这里也尝试降到10维。\n",
    "# 但请注意，这可能非常耗时，且效果不一定好。\n",
    "# 通常如果用t-SNE做分类的预处理（不常见），可能会选择非常低的维度（如2或3）。\n",
    "\n",
    "# n_components_tsne = 10 # 与PCA的例子保持一致，但计算量会很大\n",
    "n_components_tsne = 2    # 更典型的t-SNE用于分类的维度，如果想快速看到结果\n",
    "                         # 如果你想严格对比PCA的10维，可以将这里改为10，但会很慢\n",
    "\n",
    "\n",
    "\n",
    "# 对训练集进行 fit_transform\n",
    "tsne_model_train = TSNE(n_components=n_components_tsne,\n",
    "                        perplexity=30,    # 常用的困惑度值\n",
    "                        n_iter=1000,      # 足够的迭代次数\n",
    "                        init='pca',       # 使用PCA初始化，通常更稳定\n",
    "                        learning_rate='auto', # 自动学习率 (sklearn >= 1.2)\n",
    "                        random_state=42,  # 保证结果可复现\n",
    "                        n_jobs=-1)        # 使用所有CPU核心\n",
    "print(\"正在对训练集进行 t-SNE fit_transform...\")\n",
    "start_tsne_fit_train = time.time()\n",
    "X_train_tsne = tsne_model_train.fit_transform(X_train_scaled_tsne)\n",
    "end_tsne_fit_train = time.time()\n",
    "print(f\"训练集 t-SNE fit_transform 完成，耗时: {end_tsne_fit_train - start_tsne_fit_train:.2f} 秒\")\n",
    "\n",
    "\n",
    "# 对测试集进行 fit_transform\n",
    "# 再次强调：这是独立于训练集的变换\n",
    "tsne_model_test = TSNE(n_components=n_components_tsne,\n",
    "                       perplexity=30,\n",
    "                       n_iter=1000,\n",
    "                       init='pca',\n",
    "                       learning_rate='auto',\n",
    "                       random_state=42, # 保持参数一致，但数据不同，结果也不同\n",
    "                       n_jobs=-1)\n",
    "print(\"正在对测试集进行 t-SNE fit_transform...\")\n",
    "start_tsne_fit_test = time.time()\n",
    "X_test_tsne = tsne_model_test.fit_transform(X_test_scaled_tsne) # 注意这里是 X_test_scaled_tsne\n",
    "end_tsne_fit_test = time.time()\n",
    "print(f\"测试集 t-SNE fit_transform 完成，耗时: {end_tsne_fit_test - start_tsne_fit_test:.2f} 秒\")\n",
    "\n",
    "print(f\"t-SNE降维后，训练集形状: {X_train_tsne.shape}, 测试集形状: {X_test_tsne.shape}\")\n",
    "\n",
    "start_time_tsne_rf = time.time()\n",
    "# 步骤 3: 训练随机森林分类器\n",
    "rf_model_tsne = RandomForestClassifier(random_state=42)\n",
    "rf_model_tsne.fit(X_train_tsne, y_train)\n",
    "\n",
    "# 步骤 4: 在测试集上预测\n",
    "rf_pred_tsne_manual = rf_model_tsne.predict(X_test_tsne)\n",
    "end_time_tsne_rf = time.time()\n",
    "\n",
    "print(f\"t-SNE降维数据上，随机森林训练与预测耗时: {end_time_tsne_rf - start_time_tsne_rf:.4f} 秒\")\n",
    "total_tsne_time = (end_tsne_fit_train - start_tsne_fit_train) + \\\n",
    "                  (end_tsne_fit_test - start_tsne_fit_test) + \\\n",
    "                  (end_time_tsne_rf - start_time_tsne_rf)\n",
    "print(f\"t-SNE 总耗时 (包括两次fit_transform和RF): {total_tsne_time:.2f} 秒\")\n",
    "\n",
    "\n",
    "print(\"\\n手动 t-SNE + 随机森林 在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, rf_pred_tsne_manual))\n",
    "print(\"手动 t-SNE + 随机森林 在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, rf_pred_tsne_manual))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3280b48750e5b723",
   "metadata": {},
   "source": [
    "\n",
    "## LDA：利用类别信息最大化可分性\n",
    "\n",
    "LDA 是一种**有监督的线性降维方法**，目标不是保留方差，而是**让不同类别尽可能分开、同类样本尽可能聚集**。\n",
    "它通过最大化“类间散布 / 类内散布”的比值来寻找最具判别力的投影方向。\n",
    "\n",
    "### 关键特性\n",
    "\n",
    "* **利用标签信息**：投影方向完全由类别结构决定，这是与 PCA 最大的区别。\n",
    "* **降维上限固定**：最多降到 `n_classes − 1` 维（例如二分类只能到 1 维）。\n",
    "* **线性组合**：生成判别特征，是原始特征的线性变换。\n",
    "\n",
    "### 适用场景\n",
    "\n",
    "适合作为分类任务的预处理步骤，获取判别性强的低维特征或进行可视化（2–3 类时尤其直观）。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff074f4e87305ce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:17:48.463153Z",
     "start_time": "2025-11-30T12:17:46.845668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. LDA 降维 + 随机森林 ---\n",
      "原始特征数: 30, 类别数: 2\n",
      "LDA 最多可降至 1 维。\n",
      "目标降维维度: 10 维。\n",
      "本次 LDA 将实际降至 1 维。\n",
      "LDA降维后，训练集形状: (6000, 1), 测试集形状: (1500, 1)\n",
      "LDA降维数据上，随机森林训练与预测耗时: 1.5058 秒\n",
      "\n",
      "手动 LDA + 随机森林 在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1059\n",
      "           1       0.47      0.47      0.47       441\n",
      "\n",
      "    accuracy                           0.69      1500\n",
      "   macro avg       0.63      0.63      0.63      1500\n",
      "weighted avg       0.69      0.69      0.69      1500\n",
      "\n",
      "手动 LDA + 随机森林 在测试集上的混淆矩阵：\n",
      "[[828 231]\n",
      " [233 208]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "import numpy as np\n",
    "# 假设你已经导入了 matplotlib 和 seaborn 用于绘图 (如果需要)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D # 如果需要3D绘图\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n--- 4. LDA 降维 + 随机森林 ---\")\n",
    "\n",
    "# 步骤 1: 特征缩放\n",
    "scaler_lda = StandardScaler()\n",
    "X_train_scaled_lda = scaler_lda.fit_transform(X_train)\n",
    "X_test_scaled_lda = scaler_lda.transform(X_test) # 使用在训练集上fit的scaler\n",
    "\n",
    "# 步骤 2: LDA 降维\n",
    "n_features = X_train_scaled_lda.shape[1]\n",
    "if hasattr(y_train, 'nunique'):\n",
    "    n_classes = y_train.nunique()\n",
    "elif isinstance(y_train, np.ndarray):\n",
    "    n_classes = len(np.unique(y_train))\n",
    "else:\n",
    "    n_classes = len(set(y_train))\n",
    "\n",
    "max_lda_components = min(n_features, n_classes - 1)\n",
    "\n",
    "# 设置目标降维维度\n",
    "n_components_lda_target = 10\n",
    "\n",
    "if max_lda_components < 1:\n",
    "    print(f\"LDA 不适用，因为类别数 ({n_classes})太少，无法产生至少1个判别组件。\")\n",
    "    X_train_lda = X_train_scaled_lda.copy() # 使用缩放后的原始特征\n",
    "    X_test_lda = X_test_scaled_lda.copy()   # 使用缩放后的原始特征\n",
    "    actual_n_components_lda = n_features\n",
    "    print(\"将使用缩放后的原始特征进行后续操作。\")\n",
    "else:\n",
    "    # 实际使用的组件数不能超过LDA的上限，也不能超过我们的目标（如果目标更小）\n",
    "    actual_n_components_lda = min(n_components_lda_target, max_lda_components)\n",
    "    if actual_n_components_lda < 1: # 这种情况理论上不会发生，因为上面已经检查了 max_lda_components < 1\n",
    "        print(f\"计算得到的实际LDA组件数 ({actual_n_components_lda}) 小于1，LDA不适用。\")\n",
    "        X_train_lda = X_train_scaled_lda.copy()\n",
    "        X_test_lda = X_test_scaled_lda.copy()\n",
    "        actual_n_components_lda = n_features\n",
    "        print(\"将使用缩放后的原始特征进行后续操作。\")\n",
    "    else:\n",
    "        print(f\"原始特征数: {n_features}, 类别数: {n_classes}\")\n",
    "        print(f\"LDA 最多可降至 {max_lda_components} 维。\")\n",
    "        print(f\"目标降维维度: {n_components_lda_target} 维。\")\n",
    "        print(f\"本次 LDA 将实际降至 {actual_n_components_lda} 维。\")\n",
    "\n",
    "        lda_manual = LinearDiscriminantAnalysis(n_components=actual_n_components_lda, solver='svd')\n",
    "        X_train_lda = lda_manual.fit_transform(X_train_scaled_lda, y_train)\n",
    "        X_test_lda = lda_manual.transform(X_test_scaled_lda)\n",
    "\n",
    "print(f\"LDA降维后，训练集形状: {X_train_lda.shape}, 测试集形状: {X_test_lda.shape}\")\n",
    "\n",
    "start_time_lda_rf = time.time()\n",
    "# 步骤 3: 训练随机森林分类器\n",
    "rf_model_lda = RandomForestClassifier(random_state=42)\n",
    "rf_model_lda.fit(X_train_lda, y_train)\n",
    "\n",
    "# 步骤 4: 在测试集上预测\n",
    "rf_pred_lda_manual = rf_model_lda.predict(X_test_lda)\n",
    "end_time_lda_rf = time.time()\n",
    "\n",
    "print(f\"LDA降维数据上，随机森林训练与预测耗时: {end_time_lda_rf - start_time_lda_rf:.4f} 秒\")\n",
    "\n",
    "print(\"\\n手动 LDA + 随机森林 在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, rf_pred_lda_manual))\n",
    "print(\"手动 LDA + 随机森林 在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, rf_pred_lda_manual))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1878874df65800db",
   "metadata": {},
   "source": [
    "| 方法        | 类型      | 主要目标                  | 是否用到标签 | 变换方式        | 保留的结构     | 降维限制                      | 典型用途               |\n",
    "| --------- | ------- | --------------------- | ------ | ----------- | --------- | ------------------------- | ------------------ |\n",
    "| **PCA**   | 线性、无监督  | 最大化数据整体方差             | ❌ 不使用  | 线性投影（正交主成分） | 全局结构、方差方向 | 受限于特征数                    | 特征压缩、降噪、线性结构可视化    |\n",
    "| **LDA**   | 线性、有监督  | 最大化类别可分性（类间距离大、类内距离小） | ✅ 使用标签 | 线性投影（判别方向）  | 类别分离结构    | **最多到 `n_classes - 1` 维** | 分类任务预处理、判别特征提取、可视化 |\n",
    "| **t-SNE** | 非线性、无监督 | 保留局部邻域关系              | ❌ 不使用  | 非线性嵌入       | 局部簇结构     | 一般用于 2D/3D 可视化            | 高维数据可视化、发现隐藏群落     |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
