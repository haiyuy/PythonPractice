{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e66fc88c",
   "metadata": {},
   "source": [
    "# Day 54 - Inception 网络及其思考\n",
    "\n",
    "**学习目标：**\n",
    "- 理解 Inception 网络的核心设计理念\n",
    "- 掌握多尺度特征融合的实现方法\n",
    "- 了解特征融合的常见方式\n",
    "- 学习卷积核变体与感受野的概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc51f92",
   "metadata": {},
   "source": [
    "---\n",
    "## 一、Inception 网络介绍\n",
    "\n",
    "### 1.1 背景与动机\n",
    "\n",
    "Inception 网络（也称为 GoogLeNet）是 Google 团队在 2014 年提出的经典卷积神经网络架构。\n",
    "\n",
    "> **参考资料：** [传统计算机视觉的发展史](https://blog.csdn.net/qq_42604176/article/details/108588366)\n",
    "\n",
    "从历史发展来看，Inception 网络实际上出现在 ResNet 之前。之所以在学习 ResNet 后再介绍它，是因为 Inception 引出了重要的**特征融合**和**特征并行处理**思想。\n",
    "\n",
    "### 1.2 核心设计理念\n",
    "\n",
    "Inception 网络的核心设计理念是 **\"并行的多尺度融合\"**，具体表现为：\n",
    "\n",
    "- 在同一层网络中使用多个不同大小的卷积核（如 1x1、3x3、5x5）\n",
    "- 结合池化操作，从不同尺度提取图像特征\n",
    "- 将这些特征进行融合\n",
    "- 在不增加过多计算量的情况下，获得更丰富的特征表达\n",
    "\n",
    "### 1.3 Inception 模块的组成\n",
    "\n",
    "Inception 模块是 Inception 网络的基本组成单元。\n",
    "\n",
    "**关键洞察：** 在同样的步长下：\n",
    "- 卷积核越小，下采样率越低，保留的图片像素越多\n",
    "- 卷积核越大，越能捕捉像素周围的信息\n",
    "\n",
    "一个典型的 Inception 模块包含以下四个并行分支：\n",
    "\n",
    "| 分支 | 描述 | 作用 |\n",
    "|------|------|------|\n",
    "| **1x1 卷积分支** | 用于降维 | 减少后续卷积的计算量，同时提取局部特征 |\n",
    "| **3x3 卷积分支** | 中等尺度卷积 | 捕捉中等尺度的特征 |\n",
    "| **5x5 卷积分支** | 较大尺度卷积 | 捕捉较大尺度的特征 |\n",
    "| **池化分支** | 最大/平均池化 | 保留图像的全局信息 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inception_arch",
   "metadata": {},
   "source": [
    "---\n",
    "## 二、Inception 网络架构\n",
    "\n",
    "### 2.1 定义 Inception 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd16965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    \"\"\"\n",
    "    Inception 模块：实现多尺度特征并行提取与融合\n",
    "    \n",
    "    该模块包含四个并行分支：\n",
    "    - 1x1 卷积分支：降维并提取通道间特征关系\n",
    "    - 3x3 卷积分支：捕捉中等尺度特征\n",
    "    - 5x5 卷积分支：捕捉大尺度特征\n",
    "    - 池化分支：保留全局信息\n",
    "    \n",
    "    参数:\n",
    "        in_channels: 输入特征图的通道数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels):\n",
    "        super(Inception, self).__init__()\n",
    "        \n",
    "        # ========== 分支1：1x1 卷积 ==========\n",
    "        # 作用：降维并提取通道间特征关系\n",
    "        self.branch1x1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # ========== 分支2：3x3 卷积 ==========\n",
    "        # 作用：先降维，再用 3x3 卷积捕捉中等尺度特征\n",
    "        self.branch3x3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 96, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(96, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # ========== 分支3：5x5 卷积 ==========\n",
    "        # 作用：较大的感受野用于提取更全局的结构信息\n",
    "        self.branch5x5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # ========== 分支4：池化分支 ==========\n",
    "        # 作用：通过池化操作保留全局信息并降维\n",
    "        self.branch_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播：并行计算四个分支并在通道维度拼接\n",
    "        \n",
    "        输出通道数 = 64 + 128 + 32 + 32 = 256\n",
    "        \"\"\"\n",
    "        branch1x1 = self.branch1x1(x)      # [batch, 64, H, W]\n",
    "        branch3x3 = self.branch3x3(x)      # [batch, 128, H, W]\n",
    "        branch5x5 = self.branch5x5(x)      # [batch, 32, H, W]\n",
    "        branch_pool = self.branch_pool(x)  # [batch, 32, H, W]\n",
    "        \n",
    "        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inception_module_note",
   "metadata": {},
   "source": [
    "**维度变化：** `[B, C, H, W]` 到 `[B, 256, H, W]`\n",
    "\n",
    "无论输入通道数是多少，输出通道数固定为 256（64+128+32+32）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abea6830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: torch.Size([32, 64, 28, 28])\n",
      "输出形状: torch.Size([32, 256, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 测试 Inception 模块\n",
    "model = Inception(in_channels=64)\n",
    "input_tensor = torch.randn(32, 64, 28, 28)  # batch=32, channels=64, H=W=28\n",
    "output = model(input_tensor)\n",
    "\n",
    "print(f\"输入形状: {input_tensor.shape}\")\n",
    "print(f\"输出形状: {output.shape}\")  # 预期: [32, 256, 28, 28]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b98cb2",
   "metadata": {},
   "source": [
    "**设计要点：**\n",
    "\n",
    "Inception 模块中不同的卷积核和步长最后输出**同样尺寸**的特征图，这是经过精心设计的：\n",
    "- 必须保证空间尺寸对齐\n",
    "- 才能在通道维度正确拼接（concat）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd4086",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.2 特征融合方法\n",
    "\n",
    "Inception 模块采用 **Concat（拼接）** 的方式将不同尺度的特征融合在一起。\n",
    "\n",
    "#### Concat 拼接的特点：\n",
    "- 通道数增加\n",
    "- 空间尺寸（H, W）保持不变\n",
    "- 每个通道的数值保持独立，没有加法运算\n",
    "\n",
    "#### 深度学习中常见的特征融合方式：\n",
    "\n",
    "**1. 逐元素相加（残差连接）**\n",
    "```python\n",
    "output = x + self.residual_block(x)\n",
    "```\n",
    "\n",
    "**2. 逐元素相乘（注意力机制）**\n",
    "```python\n",
    "attention = self.ChannelAttention(features)\n",
    "weighted_features = features * attention\n",
    "```\n",
    "\n",
    "**3. 通道拼接**\n",
    "```python\n",
    "output = torch.cat([f1, f2], dim=1)\n",
    "```\n",
    "\n",
    "| 方法           | 维度变化  | 计算量    | 典型场景                |\n",
    "| ------------ | ----- | ------ | ------------------- |\n",
    "| concat       | 通道数增加 | 中      | Inception、U-Net     |\n",
    "| 逐元素相加        | 维度不变  | 低      | ResNet、DenseNet 过渡层 |\n",
    "| 逐元素相乘        | 维度不变  | 中（需权重） | 注意力机制、门控网络          |\n",
    "| 跳跃连接（concat） | 通道数增加 | 中      | U-Net、FPN           |\n",
    "| 加权融合（SE-Net） | 维度不变  | 低      | 通道特征重标定             |\n",
    "| 空间金字塔池化（SPP） | 通道数增加 | 中      | 目标检测、尺寸自适应任务        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dbbf1e",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.3 InceptionNet 网络定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d219c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionNet(nn.Module):\n",
    "    \"\"\"\n",
    "    简化版 InceptionNet：用于图像分类\n",
    "    \n",
    "    网络结构：\n",
    "    1. 卷积层（初始特征提取）\n",
    "    2. Inception 模块 x 2（多尺度特征融合）\n",
    "    3. 全局平均池化 + 全连接层（分类输出）\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(InceptionNet, self).__init__()\n",
    "        \n",
    "        # 初始卷积层\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Inception 模块\n",
    "        self.inception1 = Inception(64)\n",
    "        self.inception2 = Inception(256)\n",
    "        \n",
    "        # 分类头\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0af9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: torch.Size([1, 3, 224, 224])\n",
      "输出形状: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# 测试 InceptionNet\n",
    "model = InceptionNet(num_classes=10)\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "output = model(input_tensor)\n",
    "print(f\"输入形状: {input_tensor.shape}\")\n",
    "print(f\"输出形状: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235ebdad",
   "metadata": {},
   "source": [
    "### 2.4 Inception 网络的版本演进\n",
    "\n",
    "| 版本 | 特点 |\n",
    "|------|------|\n",
    "| **Inception v1 (GoogLeNet)** | 最初版本，引入 Inception 模块 |\n",
    "| **Inception v2** | 使用 Batch Normalization |\n",
    "| **Inception v3** | 进一步分解卷积核 |\n",
    "| **Inception v4** | 更深的网络结构 |\n",
    "| **Inception-ResNet** | 引入残差连接 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae27a444",
   "metadata": {},
   "source": [
    "---\n",
    "## 三、卷积核的变体\n",
    "\n",
    "### 3.1 感受野（Receptive Field）\n",
    "\n",
    "感受野是指在 CNN 中，神经元在原始输入图像上所对应的区域大小。\n",
    "\n",
    "**感受野计算示例**（3x3 卷积，步长 1）：\n",
    "- 第一层感受野 = 3x3\n",
    "- 第二层感受野 = 5x5（计算公式：3+3-1=5）\n",
    "\n",
    "**小卷积核的优势：**\n",
    "1. 减少参数量\n",
    "2. 引入更多非线性（多次经过激活函数）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c122af",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.2 空洞卷积（Dilated Convolution）\n",
    "\n",
    "空洞卷积在卷积核元素间插入空洞，用 dilation rate (d) 控制间隔大小。\n",
    "\n",
    "| 类型 | 描述 |\n",
    "|------|------|\n",
    "| 标准卷积（d=1） | 卷积核元素紧密排列 |\n",
    "| 空洞卷积（d>1） | 卷积核元素间插入 d-1 个空洞 |\n",
    "\n",
    "**优点：**\n",
    "- 扩大感受野而不增加参数\n",
    "- 保持空间信息（相比池化下采样）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a12f25",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.3 空洞卷积示例\n",
    "\n",
    "使用空洞卷积只需添加 `dilation` 参数：\n",
    "\n",
    "```python\n",
    "# 空洞卷积（dilation=2）\n",
    "self.conv = nn.Conv2d(16, 32, kernel_size=3, padding=2, dilation=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b20fd448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 1.835\n",
      "Epoch: 1, Batch: 200, Loss: 1.508\n",
      "Epoch: 1, Batch: 300, Loss: 1.399\n",
      "Accuracy on test set: 54.53%\n",
      "Epoch: 2, Batch: 100, Loss: 1.222\n",
      "Epoch: 2, Batch: 200, Loss: 1.184\n",
      "Epoch: 2, Batch: 300, Loss: 1.115\n",
      "Accuracy on test set: 62.45%\n",
      "Epoch: 3, Batch: 100, Loss: 1.020\n",
      "Epoch: 3, Batch: 200, Loss: 1.008\n",
      "Epoch: 3, Batch: 300, Loss: 0.986\n",
      "Accuracy on test set: 65.47%\n",
      "Epoch: 4, Batch: 100, Loss: 0.895\n",
      "Epoch: 4, Batch: 200, Loss: 0.899\n",
      "Epoch: 4, Batch: 300, Loss: 0.873\n",
      "Accuracy on test set: 66.70%\n",
      "Epoch: 5, Batch: 100, Loss: 0.788\n",
      "Epoch: 5, Batch: 200, Loss: 0.783\n",
      "Epoch: 5, Batch: 300, Loss: 0.796\n",
      "Accuracy on test set: 70.19%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 加载 CIFAR-10 数据集\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "class SimpleCNNWithDilation(nn.Module):\n",
    "    \"\"\"包含空洞卷积的简单 CNN 模型\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNNWithDilation, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        # 空洞卷积，dilation=2\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=2, dilation=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 训练配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNNWithDilation().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy on test set: {100 * correct / total:.2f}%')\n",
    "\n",
    "\n",
    "# 训练 5 个 epoch\n",
    "for epoch in range(5):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a27eaa8",
   "metadata": {},
   "source": [
    "---\n",
    "## 四、总结\n",
    "\n",
    "**本节要点回顾：**\n",
    "\n",
    "1. **Inception 网络核心思想**\n",
    "   - 并行的多尺度特征融合\n",
    "   - 使用不同大小的卷积核（1x1、3x3、5x5）+ 池化\n",
    "   - 通过 1x1 卷积降维减少计算量\n",
    "\n",
    "2. **特征融合方式**\n",
    "   - Concat（通道拼接）\n",
    "   - 逐元素相加（残差连接）\n",
    "   - 逐元素相乘（注意力机制）\n",
    "\n",
    "3. **感受野与卷积变体**\n",
    "   - 感受野决定了网络能\"看到\"的范围\n",
    "   - 空洞卷积可以在不增加参数的情况下扩大感受野"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
