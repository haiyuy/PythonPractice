{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DAY 46 TensorBoard 使用介绍\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 学习目标\n",
        "- 理解 TensorBoard 的作用与数据流转方式\n",
        "- 掌握 SummaryWriter 的核心用法（标量、图像、直方图、计算图）\n",
        "- 通过 CIFAR-10 的 MLP / CNN 实战，生成可视化日志\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 一、TensorBoard 概览\n",
        "TensorBoard 是深度学习训练过程的可视化面板，可用于：\n",
        "- 观察 loss / acc 曲线，判断收敛或过拟合\n",
        "- 查看模型结构图，快速确认网络连接\n",
        "- 记录样本图像、参数分布，辅助排查训练异常\n",
        "\n",
        "工作原理：训练时把指标、图像、直方图等写入日志文件（*.tfevents），TensorBoard 读取该目录并在网页展示。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 二、准备环境与数据\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples: 5000, Test samples: 1000\n",
            "Sample batch shape: torch.Size([128, 3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# 为了演示更快，这里截取少量样本；想要完整训练可去掉 Subset\n",
        "def get_loaders(batch_size=128, limit_train=5000, limit_test=1000):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    ])\n",
        "\n",
        "    train_set = torchvision.datasets.CIFAR10(root='data', train=True, download=True, transform=transform)\n",
        "    test_set = torchvision.datasets.CIFAR10(root='data', train=False, download=True, transform=transform)\n",
        "\n",
        "    if limit_train:\n",
        "        train_set = Subset(train_set, range(limit_train))\n",
        "    if limit_test:\n",
        "        test_set = Subset(test_set, range(limit_test))\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    \n",
        "    print(f'Train samples: {len(train_set)}, Test samples: {len(test_set)}')\n",
        "    return train_loader, test_loader\n",
        "\n",
        "train_loader, test_loader = get_loaders()\n",
        "images, labels = next(iter(train_loader))\n",
        "print('Sample batch shape:', images.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 三、创建 SummaryWriter 与基础可视化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged sample images to runs/day46_intro\n"
          ]
        }
      ],
      "source": [
        "# 创建 writer，日志会自动追加编号避免覆盖\n",
        "writer = SummaryWriter(log_dir='runs/day46_intro')\n",
        "\n",
        "# 记录一组训练图像\n",
        "img_grid = make_grid(images[:16], nrow=8, normalize=True, scale_each=True)\n",
        "writer.add_image('TrainSamples', img_grid, global_step=0)\n",
        "writer.flush()\n",
        "print('Logged sample images to runs/day46_intro')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 记录模型结构（Graph）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged MLP graph\n"
          ]
        }
      ],
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3 * 32 * 32, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "mlp = SimpleMLP().to(device)\n",
        "dummy_input = images[:1].to(device)\n",
        "writer.add_graph(mlp, dummy_input)\n",
        "writer.flush()\n",
        "print('Logged MLP graph')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 四、MLP 训练 + TensorBoard 日志\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss=2.0121, acc=0.3234\n",
            "Epoch 2: loss=1.6385, acc=0.4348\n"
          ]
        }
      ],
      "source": [
        "def train_mlp(epochs=2, log_dir='runs/day46_mlp'):\n",
        "    model = SimpleMLP().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    writer = SummaryWriter(log_dir=log_dir)\n",
        "    writer.add_graph(model, images[:1].to(device))\n",
        "\n",
        "    global_step = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            if batch_idx % 50 == 0:\n",
        "                writer.add_scalar('Loss/train', loss.item(), global_step)\n",
        "                writer.add_scalar('Acc/train', correct / total, global_step)\n",
        "            global_step += 1\n",
        "\n",
        "        epoch_loss = running_loss / total\n",
        "        epoch_acc = correct / total\n",
        "        writer.add_scalar('Epoch/Loss', epoch_loss, epoch)\n",
        "        writer.add_scalar('Epoch/Acc', epoch_acc, epoch)\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                writer.add_histogram(name, param, epoch)\n",
        "\n",
        "        print(f'Epoch {epoch+1}: loss={epoch_loss:.4f}, acc={epoch_acc:.4f}')\n",
        "\n",
        "    writer.close()\n",
        "    return model\n",
        "\n",
        "mlp_model = train_mlp()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 五、CNN 训练 + TensorBoard 日志\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss=1.9511, acc=0.2924\n",
            "Epoch 2: loss=1.5537, acc=0.4464\n"
          ]
        }
      ],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 8 * 8, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "def train_cnn(epochs=2, log_dir='runs/day46_cnn'):\n",
        "    model = SimpleCNN().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    writer = SummaryWriter(log_dir=log_dir)\n",
        "    writer.add_graph(model, images[:1].to(device))\n",
        "\n",
        "    global_step = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            if batch_idx % 50 == 0:\n",
        "                writer.add_scalar('Loss/train', loss.item(), global_step)\n",
        "                writer.add_scalar('Acc/train', correct / total, global_step)\n",
        "            global_step += 1\n",
        "\n",
        "        epoch_loss = running_loss / total\n",
        "        epoch_acc = correct / total\n",
        "        writer.add_scalar('Epoch/Loss', epoch_loss, epoch)\n",
        "        writer.add_scalar('Epoch/Acc', epoch_acc, epoch)\n",
        "        writer.add_histogram('features.conv1.weight', model.features[0].weight, epoch)\n",
        "        writer.add_histogram('features.conv2.weight', model.features[3].weight, epoch)\n",
        "\n",
        "        print(f'Epoch {epoch+1}: loss={epoch_loss:.4f}, acc={epoch_acc:.4f}')\n",
        "\n",
        "    writer.close()\n",
        "    return model\n",
        "\n",
        "cnn_model = train_cnn()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 六、启动 TensorBoard\n",
        "训练完成后在项目根目录执行：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tensorboard --logdir runs\n",
        "# 浏览器打开 http://localhost:6006\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 七、常见问题与建议\n",
        "- 直方图记录频率不宜过高，可按 epoch 记录减少日志体积\n",
        "- 图像可用于检查数据增强是否符合预期\n",
        "- 若曲线剧烈抖动，优先检查学习率、数据预处理和 batch size\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch-gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
